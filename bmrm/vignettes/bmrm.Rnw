\documentclass{article}

\usepackage[round]{natbib}


\begin{document}
\SweaveOpts{concordance=TRUE}
%\VignetteIndexEntry{bmrm User Manual}
%\VignetteDepends{utils}
%\VignetteDepends{tools}
%\VignetteDepends{datasets}
%\VignetteKeywords{classification, regression, machine learning, ordinal regression, SVM, structured prediction, support vector machines}
%\VignettePackage{bmrm}

\title{\emph{bmrm} user manual}
\author{Julien Prados\\ University of Geneva}
\maketitle

\section{Introduction}
Package \emph{bmrm} implements the "Bundle Methods for Regularized Risk Minimization" proposed by \cite{teo10}. This framework efficiently solves a minimization problem encountred in many machine learning algorithm where the goal is to minimze a loss function $l(w,x_i,y_i)$ on the training instances $(x_i,y_i)$, under a regularization term ($\Omega(w)$):
$$\min_{w} J(w) := \lambda \Omega(w) + R_{emp}(w),$$
$$R_{emp} := \frac{1}{m}\sum{l(x_i,y_i,w)}, \lambda > 0$$
To date, the package implements more than 10 loss functions providing access to many powerful algorithms with either l1-norm or l2-norm regularization: linear-SVM-classification (hingeLoss), multiclass-SVM (softMarginVectorLoss), epsilon-regression, ordinal-regression, max-margin-fbeta-classification, quantile-regression, etc. Furthermore, flexibility of the framework makes it particulary easy to implement custom loss function for all your needs.

\section{Quick Start: \emph{bmrm} for iris classification}
This section shows how to use \emph{bmrm} to train several classification algorithms on \emph{iris} dataset. 

\subsection{Linear support vector machine (SVM)}
To simplify the dataset and facilitate plotting, we consider only 2 variables in this section. Additionally, as SVM is a binary classifier, we limit the iris dataset to 2 classes. Finally, we add a constant variable to learn the linear intercept.
<<>>=
  require(bmrm)
  x <- subset(iris,Species%in%c("setosa","versicolor"))
  y <- x$Species[drop=TRUE]
  x <- cbind(1,data.matrix(x[1:2]))
@
On this dataset, 3 linear classfiers are learned: linear-SVM with L1-norm regularization, linear-SVM with L2-norm regularization, max-margin-f1-classification with L1-regularization.
<<message=FALSE,results=hide>>=
  models <- list(
    svm_L1 = bmrm(hingeLoss(x,y),LAMBDA=0.01,regfun='l1'),
    svm_L2 = bmrm(hingeLoss(x,y),LAMBDA=0.1,regfun='l2'),
    f1_L1 = bmrm(fbetaLoss(x,y),LAMBDA=0.01,regfun='l1')
  )
@

The models learn by above algorithms are shown in figure~\ref{fig:iris_svm}

\begin{figure}[h]
\begin{center}
<<fig=TRUE,out.width=15,out.height=10,dev="png",echo=FALSE,fig.width=7,fig.height=5>>=
  # -- Plot the dataset and the predictions
  plot(x[,-1],pch=as.integer(y),main="dataset & hyperplanes")
  legend('bottomright',legend=names(models),col=seq_along(models),lty=1,cex=0.75,lwd=3)
  for(i in seq_along(models)) {
    w <- models[[i]]
    if (w[3]!=0) abline(-w[1]/w[3],-w[2]/w[3],col=i,lwd=3)
  }
@
\end{center}
\caption{\label{fig:iris_svm}Comparison of the decision surface of the 3 linear models trained on iris dataset.}
\end{figure}

\subsection{Multiclass SVM}
The previous section shows how to use bmrm for binary classification of iris dataset. Here we show how to perform multiclass-SVM on iris dataset.

\begin{figure}[h]
\begin{center}
<<fig=TRUE,out.width=15,out.height=10,dev="png",fig.width=7,fig.height=5,results=hide,echo=TRUE>>=
  x <- cbind(10,data.matrix(iris[1:4]))
  y <- iris$Species
  w <- bmrm(softMarginVectorLoss(x,y),LAMBDA=1,regfun="l1")
  w <- matrix(w,ncol=nlevels(y))
  f <- x %*% w
  matplot(f,type="o",ylab="Multiclass SVM prediction",xlab="instance")
@
\end{center}
\caption{Result of multiclass SVM prediction.}
\end{figure}

<<echo=TRUE>>=
  # classification performance on the training set
  table(max.col(f),y)
@


\section{Customized loss function}


\section{bmrm or nrbm ?}



\bibliographystyle{jss}
\bibliography{bmrm}


\end{document}